{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Egeria Logo](https://raw.githubusercontent.com/odpi/egeria/master/assets/img/ODPi_Egeria_Logo_color.png)\n",
    "\n",
    "### Egeria Hands-On Lab\n",
    "# Welcome to the Performance Test Suite Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Egeria is an open source project that provides open standards and implementation libraries to connect tools, catalogs and platforms together so they can share information (called metadata) about data and the technology that supports it.\n",
    "\n",
    "In this hands-on lab you will get a chance to work with the performance test suite that is used to measure the performance of a technology acting as an Egeria metadata repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Performance Suite \n",
    "\n",
    "The Performance Suite can be used to test a Repository Connector to record the performance of its various repository methods.\n",
    "\n",
    "There are a number of different performance profiles, each intended to measure the performance of one fairly granular area of performance of a repository. The suite will attempt to invoke all metadata methods a number of times, with a variety of parameters, to attempt to identify any potential performance bottlenecks or troublesome scenarios in the repository.\n",
    "\n",
    "Of course, many of the methods are optional: the suite will therefore simply record results for those methods it is able to invoke, and mark those it is not as unsupported.\n",
    "\n",
    "**It is important to note that since this suite focuses on performance, it will not necessarily exercise every potential edge case or do an intensive verification that every result from a method call is precisely correct: these should still be confirmed through the [Repository Workbench](run-conformance-test-suite.ipynb).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring and running the Performance Suite \n",
    "\n",
    "We'll come back to the profiles later, but for now let's configure and run the Performance Suite.\n",
    "\n",
    "We're going to need a pair of OMAG Servers - one to run the repository under test, the other to run the workbench. The servers need to join the same cohort.\n",
    "\n",
    "![CTS-Cohort.png](../images/CTS-Cohort.png)\n",
    "> **Figure 1:** Cohort for conformance testing\n",
    "\n",
    "When the one running the workbench sees the cohort registration of the server under test, it runs the workbench tests against that server's repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting up the Egeria platforms\n",
    "\n",
    "We'll start one OMAG Server Platform on which to run both the servers.\n",
    "We also need Apache Zookeeper and Apache Kafka.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../common/globals.ipynb\n",
    "\n",
    "import requests\n",
    "import pprint\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Disable warnings about self-signed certificates\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "ctsPlatformURL = os.environ.get('ctsPlatformURL','https://localhost:9445')\n",
    "\n",
    "def checkServerPlatform(testPlatformName, testPlatformURL):\n",
    "    response = requests.get(testPlatformURL + \"/open-metadata/platform-services/users/garygeeke/server-platform/origin/\")\n",
    "    if response.status_code == 200:\n",
    "        print(\"   ...\", testPlatformName, \"at\", testPlatformURL, \"is active - ready to begin\")\n",
    "    else:\n",
    "        print(\"   ...\", testPlatformName, \"at\", testPlatformURL, \"is down - start it before proceeding\")\n",
    "\n",
    "print (\"\\nChecking OMAG Server Platform availability...\")\n",
    "checkServerPlatform(\"CTS OMAG Server Platform\", ctsPlatformURL)\n",
    "\n",
    "print (\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the Servers\n",
    "\n",
    "We're going to configure both the servers in the diagram above.\n",
    "\n",
    "It's useful to create some generally useful definitions here.\n",
    "\n",
    "Knowing both server names up front will be handy for when we configure the workbench.\n",
    "\n",
    "To configure the servers we'll need a common cohort name and event bus configuration. \n",
    "We can let the CTS server default to using a local in-memory repository.\n",
    "The CTS server does not need to run any Access Services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctsServerName    = \"CTS_Server\"\n",
    "sutServerName    = \"SUT_Server\"\n",
    "devCohort        = \"devCohort\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to pass a couple of JSON request bodies - so let's set up a reusable header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonContentHeader = {'content-type':'application/json'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need a JSON request body for configuration of the event bus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventBusURLroot   = os.environ.get('eventBusURLroot', 'localhost:9092')\n",
    "\n",
    "eventBusBody      = {\n",
    "    \"producer\": {\n",
    "        \"bootstrap.servers\": eventBusURLroot\n",
    "    },\n",
    "    \"consumer\":{\n",
    "        \"bootstrap.servers\": eventBusURLroot\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also need a JSON request body for configuration of the workbench. This can be used to set a number of parameters related to the volumes that should be used in the tests:\n",
    "\n",
    "- `instancesPerType` defines the number of instances of each Egeria type that should be created: both a homed copy and a reference copy of each will be created, so the total number of instances created will in reality be 2x this number. For example, setting this to `5` for a repository that supports 500 types will generate 5000 instances of metadata (5 x 2 x 500).\n",
    "- `maxSearchResults` defines the number of results to retrieve in each page for a search request. Some scenarios will only attempt to retrieve the initial page of results, while others will cycle through every page to test the performance of paging and count the total number of instances found in the environment.\n",
    "- `waitBetweenScenarios` can be used to introduce a delay between write operations and read operations, for example if testing a repository that provides eventual consistency of its search indexes in order to improve its write (ingestion) performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbenchConfigBody = {\n",
    "    \"class\"                  : \"RepositoryPerformanceWorkbenchConfig\",\n",
    "    \"tutRepositoryServerName\": sutServerName,\n",
    "    \"instancesPerType\"       : 5,\n",
    "    \"maxSearchResults\"       : 2,\n",
    "    \"waitBetweenScenarios\"   : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a userId for the configuration commands. You could change this to a name you choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adminUserId      = \"garygeeke\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform configuration operations through the administrative interface provided by the ctsPlatformURL.\n",
    "\n",
    "The URLs for the configuration REST APIs have a common structure and begin with the following root:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adminPlatformURL = ctsPlatformURL\n",
    "\n",
    "adminCommandURLRoot = adminPlatformURL + '/open-metadata/admin-services/users/' + adminUserId + '/servers/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What follows are descriptions and coded requests to configure each server.  There are a lot of common steps \n",
    "involved in configuring a metadata server, so we first define some simple \n",
    "functions that can be re-used in later steps for configuring each server.\n",
    "\n",
    "Each function returns True or False to indicate whether it was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postAndPrintResult(url, json=None, headers=None):\n",
    "    print(\"   ...... (POST\", url, \")\")\n",
    "    response = requests.post(url, json=json, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        print(\"   ...... Success. Response: \", response.json())\n",
    "        return True\n",
    "    else:\n",
    "        print(\"   ...... Failed. Response: \", response.json())\n",
    "        return False\n",
    "    \n",
    "def getAndPrintResult(url, json=None, headers=None):\n",
    "    print(\"   ...... (GET\", url, \")\")\n",
    "    response = requests.get(url, json=json, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        print(\"   ...... Success. Response: \", response.json())\n",
    "        return True\n",
    "    else:\n",
    "        print(\"   ...... Failed. Response: \", response.json())\n",
    "        return False\n",
    "\n",
    "def getResult(url, json=None, headers=None):\n",
    "    print(\"\\n   ...... (GET\", url, \")\")\n",
    "    try:\n",
    "        response = requests.get(url, json=json, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            if response.json()['relatedHTTPCode'] == 200:\n",
    "                return response.json()\n",
    "        return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print (\"   ...... FAILED - http request threw an exception: \", e)\n",
    "        return None    \n",
    "\n",
    "def configurePlatformURL(serverName, serverPlatform):\n",
    "    print(\"\\n   ... Configuring the platform the server will run on...\")\n",
    "    url = adminCommandURLRoot + serverName + '/server-url-root?url=' + serverPlatform\n",
    "    return postAndPrintResult(url)\n",
    "\n",
    "def configureServerType(serverName, serverType):\n",
    "    print (\"\\n   ... Configuring the server's type...\")\n",
    "    url = adminCommandURLRoot + serverName + '/server-type?typeName=' + serverType\n",
    "    return postAndPrintResult(url)\n",
    "\n",
    "def configureUserId(serverName, userId):\n",
    "    print (\"\\n   ... Configuring the server's userId...\")\n",
    "    url = adminCommandURLRoot + serverName + '/server-user-id?id=' + userId\n",
    "    return postAndPrintResult(url)\n",
    "\n",
    "def configurePassword(serverName, password):\n",
    "    print (\"\\n   ... Configuring the server's password (optional)...\")\n",
    "    url = adminCommandURLRoot + serverName + '/server-user-password?password=' + password\n",
    "    return postAndPrintResult(url)\n",
    "\n",
    "def configureMetadataRepository(serverName, repositoryType):\n",
    "    print (\"\\n   ... Configuring the metadata repository...\")\n",
    "    url = adminCommandURLRoot + serverName + '/local-repository/mode/' + repositoryType\n",
    "    return postAndPrintResult(url)\n",
    "\n",
    "def configureDescriptiveName(serverName, collectionName):\n",
    "    print (\"\\n   ... Configuring the short descriptive name of the metadata stored in this server...\")\n",
    "    url = adminCommandURLRoot + serverName + '/local-repository/metadata-collection-name/' + collectionName\n",
    "    return postAndPrintResult(url)\n",
    "\n",
    "def configureEventBus(serverName, busBody):\n",
    "    print (\"\\n   ... Configuring the event bus for this server...\")\n",
    "    url = adminCommandURLRoot + serverName + '/event-bus'\n",
    "    return postAndPrintResult(url, json=busBody, headers=jsonContentHeader)\n",
    "\n",
    "def configureCohortMembership(serverName, cohortName):\n",
    "    print (\"\\n   ... Configuring the membership of the cohort...\")\n",
    "    url = adminCommandURLRoot + serverName + '/cohorts/' + cohortName\n",
    "    return postAndPrintResult(url)\n",
    "    \n",
    "def configureRepositoryWorkbench(serverName, workbenchBody):\n",
    "    print (\"\\n   ... Configuring the repository workbench for this server...\")\n",
    "    url = adminCommandURLRoot + serverName + '/conformance-suite-workbenches/repository-workbench/performance'\n",
    "    return postAndPrintResult(url, json=workbenchBody, headers=jsonContentHeader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the CTS Server\n",
    "\n",
    "We're going to configure the CTS Server from the diagram above. The CTS Server is the one that runs the repository performance workbench.\n",
    "\n",
    "The server will default to using a local in-memory repository.\n",
    "The CTS server does not need to run any Access Services.\n",
    "\n",
    "Notice that when we configure the CTS Server to run the repository performance workbench, we provide the name of the server under test.\n",
    "\n",
    "First we introduce a 'success' variable which is used to monitor progress in the subsequent cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctsServerType          = \"Conformance Suite Server\"\n",
    "ctsServerUserId        = \"CTS1npa\"\n",
    "ctsServerPassword      = \"CTS1passw0rd\"\n",
    "ctsServerPlatform      = ctsPlatformURL\n",
    "\n",
    "\n",
    "print(\"Configuring \" + ctsServerName + \"...\")\n",
    "\n",
    "if (success):\n",
    "    success = configurePlatformURL(ctsServerName, ctsServerPlatform)\n",
    "if (success):\n",
    "    success = configureServerType(ctsServerName, ctsServerType)\n",
    "if (success):\n",
    "    success = configureUserId(ctsServerName, ctsServerUserId)\n",
    "if (success):\n",
    "    success = configurePassword(ctsServerName, ctsServerPassword)\n",
    "if (success):\n",
    "    success = configureEventBus(ctsServerName, eventBusBody)\n",
    "if (success):\n",
    "    success = configureCohortMembership(ctsServerName, devCohort)\n",
    "if (success):\n",
    "    success = configureRepositoryWorkbench(ctsServerName, workbenchConfigBody)\n",
    "\n",
    "if (success):\n",
    "    print(\"\\nDone.\")\n",
    "else:\n",
    "    print(\"\\nFAILED: please check the messages above and correct before proceeding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Configuring the SUT Server (Server Under Test)\n",
    "\n",
    "Next we're going to configure the SUT Server from the diagram above. The SUT Server is the one that hosts the repository that is being tested. The SUT Server will run on the same platform as the CTS Server.\n",
    "\n",
    "The server will default to using a local in-memory repository.\n",
    "The SUT server does not need to run any Access Services.\n",
    "\n",
    "Notice that when we configure the CTS Server to run the repository workbench, we provide the name of the server under test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sutServerType                  = \"Metadata Repository Server\"\n",
    "sutServerUserId                = \"SUTnpa\"\n",
    "sutServerPassword              = \"SUTpassw0rd\"\n",
    "metadataCollectionName         = \"SUT_MDR\"\n",
    "metadataRepositoryTypeInMemory = \"in-memory-repository\"\n",
    "metadataRepositoryTypeGraph    = \"local-graph-repository\"\n",
    "\n",
    "print(\"Configuring \" + sutServerName + \"...\")\n",
    "\n",
    "if (success):\n",
    "    success = configurePlatformURL(sutServerName, ctsServerPlatform)\n",
    "if (success):\n",
    "    success = configureServerType(sutServerName, sutServerType)\n",
    "if (success):\n",
    "    success = configureUserId(sutServerName, sutServerUserId)\n",
    "if (success):\n",
    "    success = configurePassword(sutServerName, sutServerPassword)\n",
    "if (success):\n",
    "    success = configureMetadataRepository(sutServerName, metadataRepositoryTypeInMemory)\n",
    "if (success):\n",
    "    success = configureDescriptiveName(sutServerName, metadataCollectionName)\n",
    "if (success):\n",
    "    success = configureEventBus(sutServerName, eventBusBody)\n",
    "if (success):\n",
    "    success = configureCohortMembership(sutServerName, devCohort)\n",
    "\n",
    "if (success):\n",
    "    print(\"\\nDone.\")\n",
    "else:\n",
    "    print(\"\\nFAILED: please check the messages above and correct before proceeding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The commands below deploy the server configuration documents to the server platforms where the\n",
    "servers will run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deployServerToPlatform(serverName, platformURL):\n",
    "    print(\"   ... deploying\", serverName, \"to the\", platformURL, \"platform...\")\n",
    "    url = adminCommandURLRoot + serverName + '/configuration/deploy'\n",
    "    platformTarget = {\n",
    "        \"class\": \"URLRequestBody\",\n",
    "        \"urlRoot\": platformURL\n",
    "    }\n",
    "    try:\n",
    "        return postAndPrintResult(url, json=platformTarget, headers=jsonContentHeader)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print (\"   ...... FAILED - http request threw an exception: \", e)\n",
    "        return False    \n",
    "\n",
    "\n",
    "print(\"\\nDeploying server configuration documents to appropriate platforms...\")\n",
    "    \n",
    "if (success):\n",
    "    success = deployServerToPlatform(ctsServerName, ctsPlatformURL)\n",
    "if (success):\n",
    "    success = deployServerToPlatform(sutServerName, ctsPlatformURL)\n",
    "\n",
    "if (success):\n",
    "    print(\"\\nDone.\")\n",
    "else:\n",
    "    print(\"\\nFAILED: please check the messages above and correct before proceeding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the servers\n",
    "\n",
    "We'll need to define the URL for the OMRS operational services API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operationalServicesURLcore = \"/open-metadata/admin-services/users/\" + adminUserId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the CTS Server, followed by the SUT Server.\n",
    "\n",
    "When the CTS Server sees the cohort registration for the SUT Server it will start to run the workbench."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startServer(serverName, platformURL):\n",
    "    print(\"   ... starting server\", serverName, \"...\")\n",
    "    url = platformURL + operationalServicesURLcore + '/servers/' + serverName + '/instance'\n",
    "    return postAndPrintResult(url)\n",
    "\n",
    "print (\"\\nStarting the CTS server ...\")\n",
    "\n",
    "if (success):\n",
    "    success = startServer(ctsServerName, ctsPlatformURL)\n",
    "    \n",
    "# Pause to allow server to initialize fully    \n",
    "time.sleep(4)\n",
    "\n",
    "print (\"\\nStarting the SUT server ...\")\n",
    "\n",
    "if (success):\n",
    "    success = startServer(sutServerName, ctsPlatformURL)\n",
    "\n",
    "if (success):\n",
    "    print(\"\\nDone.\")\n",
    "else:\n",
    "    print(\"\\nFAILED: please check the messages above and correct before proceeding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workbench Progress\n",
    "\n",
    "The repository performance workbench runs many tests (minimally thousands, but could be many more) and it can take a while to complete -- meaning several hours.  There is no 'completion event' because when the performance suite has completed the synchronous workbench tests it continues to run and will perform asynchronous tests in responses to events that may be received within the cohort. The consequence of this is that it is not easy to know when the CTS has 'finished'. However, if you scan the output console logging from the performance suite it is possible to detect the log output:\n",
    "\n",
    "Thu Nov 21 09:11:01 GMT 2019 CTS_Server Information CONFORMANCE-SUITE-0011 The Open Metadata Conformance Workbench performance-workbench has completed its synchronous tests, further test cases may be triggered from incoming events.\n",
    "\n",
    "When this has been seen you will probably see a number of further events being processed by the CTS Server. There can be up to several hundred events - that look like the following:\n",
    "\n",
    "Thu Nov 21 09:11:03 GMT 2019 CTS_Server Event OMRS-AUDIT-8006 Processing incoming event of type DeletedEntityEvent for instance 2fd6cd97-35dd-41d9-ad2f-4d25af30033e from: OMRSEventOriginator{metadataCollectionId='f076a951-fcd0-483b-a06e-d0c7abb61b84', serverName='SUT_Server', serverType='Metadata Repository Server', organizationName='null'}\n",
    "\n",
    "Thu Nov 21 09:11:03 GMT 2019 CTS_Server Event OMRS-AUDIT-8006 Processing incoming event of type PurgedEntityEvent for instance 2fd6cd97-35dd-41d9-ad2f-4d25af30033e from: OMRSEventOriginator{metadataCollectionId='f076a951-fcd0-483b-a06e-d0c7abb61b84', serverName='SUT_Server', serverType='Metadata Repository Server', organizationName='null'}\n",
    "\n",
    "These events are usually DELETE and PURGE events relating to instances that have been cleaned up on the SUT Server. \n",
    "\n",
    "Once these events have been logged the console should go quiet. When you see this, it is possible to retrieve the workbench results from the CTS Server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polling for Status\n",
    "The following cell can be used to find out whether the workbench has completed its synchronous tests...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conformanceSuiteServicesURLcore = \"/open-metadata/conformance-suite/users/\" + adminUserId\n",
    "\n",
    "def retrieveStatus(serverName, platformURL):\n",
    "    print(\"   ... retrieving completion status from server\", serverName, \"...\")\n",
    "    url = platformURL + '/servers/' + serverName + conformanceSuiteServicesURLcore + '/status/workbenches/performance-workbench'\n",
    "    return getResult(url)\n",
    "\n",
    "print (\"\\nRetrieve performance-workbench status ...\")\n",
    "\n",
    "status_json = retrieveStatus(ctsServerName, ctsPlatformURL)\n",
    "\n",
    "if (status_json != None):\n",
    "    workbenchId = status_json['workbenchStatus']['workbenchId']\n",
    "    workbenchComplete = status_json['workbenchStatus']['workbenchComplete']\n",
    "    if (workbenchComplete == True):\n",
    "        print(\"\\nWorkbench\",workbenchId,\"is complete.\")\n",
    "    else:\n",
    "        print(\"\\nWorkbench\",workbenchId,\"has not yet completed.\")\n",
    "else:\n",
    "    print(\"\\nFAILED: please check the messages above and correct before proceeding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving the Workbench Results\n",
    "\n",
    "The performance workbench keeps the results of the testcases in memory. When the workbench is complete (see above) you can request a report of the results from the REST API on the CTS Server.\n",
    "\n",
    "The REST API has several options that supports different styles of report. Here we will request a summary report, followed by requesting the full details of each profile and test case individually. Some of the detailed profile reports can be large (several MB), so if you are running the Jupyter notebook server with its default configuration, the report may exceed the default max data rate for the notebook server. If you are not running the Egeria team's containers (docker/k8s), and you have not done so already, please restart the notebook server with the following configuration option:\n",
    "\n",
    "jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10 \n",
    "\n",
    "If the following call results in a Java Heap error you may need to increase the memory configured for your container environment, or available locally. Min 2GB, ideally 4GB additional heap space is recommended for CTS.\n",
    "\n",
    "Given the amount of detail involved, this may take a minute or two to retrieve all of the details of a completed CTS run: wait until the cell shows a number (rather than an asterisk). This indicates the cell has completed, and you should also see a final line of output that states: \\\"Done -- all details retrieved. (While it runs, you should see the output updating with the iterative REST calls that are made to retrieve each profile's or test case's details.)\n",
    "\n",
    "(Note that we have provided methods to retrieve the individual test case details; however, as there are thousands of these and the performance metrics are rather in the profile summaries, we will not actually run the retrieval of the detailed test cases.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from requests.utils import quote\n",
    "import os\n",
    "\n",
    "report_json = None\n",
    "cwd = os.getcwd()\n",
    "\n",
    "profileDir = \"profile-details\"\n",
    "testCaseDir = \"test-case-details\"\n",
    "\n",
    "conformanceSuiteServicesURLcore = \"/open-metadata/conformance-suite/users/\" + adminUserId\n",
    "\n",
    "def retrieveSummary(serverName, platformURL):\n",
    "    print(\"   ... retrieving test report summary from server\", serverName, \"...\")\n",
    "    url = platformURL + '/servers/' + serverName + conformanceSuiteServicesURLcore + '/report/summary'\n",
    "    return getResult(url)\n",
    "\n",
    "def retrieveProfileNames(serverName, platformURL):\n",
    "    print(\"   ... retrieving profile list from server\", serverName, \"...\")\n",
    "    url = platformURL + '/servers/' + serverName + conformanceSuiteServicesURLcore + '/report/profiles'\n",
    "    return getResult(url)\n",
    "\n",
    "def retrieveTestCaseIds(serverName, platformURL):\n",
    "    print(\"   ... retrieving test case list from server\", serverName, \"...\")\n",
    "    url = platformURL + '/servers/' + serverName + conformanceSuiteServicesURLcore + '/report/test-cases'\n",
    "    return getResult(url)\n",
    "\n",
    "def retrieveProfileDetails(serverName, platformURL, profileName):\n",
    "    encodedProfileName = quote(profileName)\n",
    "    url = platformURL + '/servers/' + serverName + conformanceSuiteServicesURLcore + '/report/profiles/' + encodedProfileName\n",
    "    return getResult(url)\n",
    "\n",
    "def retrieveTestCaseDetails(serverName, platformURL, testCaseId):\n",
    "    url = platformURL + '/servers/' + serverName + conformanceSuiteServicesURLcore + '/report/test-cases/' + testCaseId\n",
    "    return getResult(url)\n",
    "\n",
    "print (\"\\nRetrieve Performance Suite summary results ...\")\n",
    "\n",
    "summary_json = retrieveSummary(ctsServerName, ctsPlatformURL)\n",
    "\n",
    "if (summary_json != None):\n",
    "    with open(\"openmetadata_cts_summary.json\", 'w') as outfile:\n",
    "        json.dump(summary_json, outfile)\n",
    "    profiles = retrieveProfileNames(ctsServerName, ctsPlatformURL)\n",
    "    profileDetailsDir = cwd + os.path.sep + profileDir\n",
    "    os.makedirs(profileDetailsDir, exist_ok=True)\n",
    "    print(\"Retrieving details for each profile...\")\n",
    "    for profile in profiles['profileNames']:\n",
    "        profile_details = retrieveProfileDetails(ctsServerName, ctsPlatformURL, profile)\n",
    "        with open(profileDetailsDir + os.path.sep + profile.replace(\" \", \"_\") + \".json\", 'w') as outfile:\n",
    "            json.dump(profile_details, outfile)\n",
    "    print(\"\\nDone -- all details retrieved.\")\n",
    "else:\n",
    "    print(\"\\nFAILED: please check the messages above and correct before proceeding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conformance Profile Results\n",
    "\n",
    "The following is a summary of the status of each performance profile. To ensure that you get a complete summary, make sure you retrieve the results (as above) once the workbench has completed.\n",
    "\n",
    "(Note that this uses pandas to summarize the results table: if you have not already done so, use pip3 to install pandas and its dependencies.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from pandas import json_normalize\n",
    "\n",
    "if (summary_json != None):\n",
    "    repositoryWorkbenchResults = json_normalize(data = summary_json['testLabSummary'],\n",
    "                                                record_path =['testSummariesFromWorkbenches','profileSummaries'])\n",
    "    repositoryWorkbenchResultsSummary = repositoryWorkbenchResults[['name','description','profilePriority','conformanceStatus']]\n",
    "\n",
    "    display(repositoryWorkbenchResultsSummary.head(15))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
